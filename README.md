<div align="center">
  <img src="deepline-logo.png" alt="Deepline Logo" width="200"/>
  
  # ğŸ”¬ **Deepline MCP Server**
  
  ## **AI-Powered Data Science & MLOps Platform**
  
  *Transform your data workflows with natural language commands through Claude Desktop*
  
  [![Python](https://img.shields.io/badge/Python-3.12%2B-blue.svg)](https://python.org)
  [![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com)
  [![License](https://img.shields.io/badge/License-Hybrid-orange.svg)](#license)
  [![MCP](https://img.shields.io/badge/MCP-1.10.1-red.svg)](https://modelcontextprotocol.io)
  [![Tests](https://img.shields.io/badge/Tests-35%2F35%20Pass-brightgreen.svg)](#testing)
  
</div>

---

## ğŸ“‹ **Table of Contents**

- [âœ¨ What is Deepline?](#-what-is-deepline)
- [ğŸ¯ Key Features](#-key-features)  
- [âš¡ Quick Start](#-quick-start)
- [ğŸ“‹ Prerequisites](#-prerequisites)
- [ğŸ› ï¸ Installation](#ï¸-installation)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸ”§ Infrastructure Components](#-infrastructure-components)
- [ğŸ“– Tool Reference](#-tool-reference)
- [ğŸ”„ Workflow Examples](#-workflow-examples)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ§ª Testing](#-testing)
- [ğŸš¨ Troubleshooting](#-troubleshooting)
- [ğŸ’¡ Tips & Best Practices](#-tips--best-practices)
- [ğŸ“š Documentation](#-documentation)
- [ğŸ“„ License](#-license)
- [ğŸ“ Contact](#-contact)

---

## âœ¨ **What is Deepline?**

Deepline is a comprehensive **AI-powered data science platform** that integrates seamlessly with Claude Desktop through the Model Context Protocol (MCP). It provides **14 powerful data analysis tools** and an optional **Master Orchestrator** for natural language workflow automation.

### **ğŸ¯ Core Capabilities**

- **ğŸ“Š Data Analysis**: 14 production-ready tools for EDA, quality assessment, and ML monitoring
- **ğŸ¤– AI Workflow Orchestration**: Natural language to structured workflow translation
- **ğŸ“ˆ Model Performance Monitoring**: Real-time drift detection and performance tracking
- **ğŸ›¡ï¸ Enterprise Security**: Input sanitization, validation, and secure processing
- **ğŸ”„ Self-Contained Operation**: Works without external infrastructure dependencies

### **ğŸŒŸ Why Choose Deepline?**

- âœ… **Zero Learning Curve**: Natural language interface through Claude Desktop
- âœ… **Production Ready**: Enterprise-grade reliability with 100% test coverage (35/35 tests)
- âœ… **Self-Contained**: Works without external services (graceful fallbacks to in-memory)
- âœ… **Proven Components**: All tools tested and validated for real-world usage
- âœ… **Extensible**: Plugin architecture for custom tools and integrations

---

## ğŸ¯ **Key Features**

### **ğŸ“Š Core MCP Tools (14 Total)**

| Category | Tools | Purpose |
|----------|-------|---------|
| **Data Management** | `load_data`, `basic_info`, `list_datasets` | Dataset loading and overview |
| **Data Quality** | `missing_data_analysis`, `infer_schema`, `data_quality_report` | Quality assessment and validation |
| **Visualization** | `create_visualization` | Interactive charts and plots |
| **Statistics** | `statistical_summary`, `detect_outliers` | Descriptive analytics and anomaly detection |
| **ML Monitoring** | `drift_analysis`, `model_performance_report` | Model performance and data drift |
| **Feature Engineering** | `feature_transformation` | Box-Cox, log transforms, binning |
| **Debug Tools** | `debug_drift_summary`, `debug_perf_summary` | Development and testing utilities |

### **ğŸ¤– Master Orchestrator**

- **Natural Language Processing**: Convert plain English to structured workflows
- **Rule-Based Translation**: Instant recognition of common data science patterns
- **Security Layer**: Input sanitization with XSS prevention and prompt injection defense
- **Graceful Degradation**: Self-contained operation with intelligent infrastructure fallbacks
- **SLA Monitoring**: Real-time task and workflow monitoring with configurable thresholds

### **ğŸ“ˆ Infrastructure Components**

- **MongoDB**: Workflow persistence with graceful in-memory fallback
- **Redis**: Caching layer with graceful in-memory fallback  
- **Apache Kafka**: Event streaming for enterprise deployments
- **React Dashboard**: Real-time monitoring interface

---

## âš¡ **Quick Start**

### **ğŸš€ 5-Minute Setup**

```powershell
# 1. Clone repository
git clone https://github.com/your-org/deepline.git
cd deepline

# 2. Install dependencies
cd mcp-server
pip install -r requirements-python313.txt

# 3. Verify installation
python verify_setup.py

# 4. Launch MCP server
python launch_server.py
```

### **ğŸ”— Connect to Claude Desktop**

1. **Automatic Configuration**: The server auto-configures Claude Desktop
2. **Test Connection**: Open Claude Desktop and try:
   ```
   "Load the iris.csv dataset and show me basic info"
   ```
3. **Verify Response**: You should see data analysis results

### **ğŸš€ Launch Master Orchestrator**

```powershell
# Master Orchestrator API (Natural Language Workflows)
python -m uvicorn master_orchestrator_api:app --host 127.0.0.1 --port 8000

# Test API endpoints
curl http://127.0.0.1:8000/health

# Full Infrastructure (Enterprise)
docker-compose up -d
```

---

## ğŸ“‹ **Prerequisites**

### **System Requirements**

| Component | Requirement | Recommended |
|-----------|-------------|-------------|
| **OS** | Windows 10/11 | Windows 11 22H2+ |
| **Python** | 3.12+ | Python 3.13 |
| **Memory** | 4GB RAM | 8GB+ RAM |
| **Storage** | 2GB free space | 5GB+ free space |
| **Network** | Internet connection | Stable broadband |

### **Required Dependencies (Auto-installed)**

```python
# Core MCP Server
pandas, numpy          # Data manipulation
evidently              # ML monitoring and data quality
plotly, matplotlib     # Visualization
scikit-learn           # Machine learning utilities
missingno              # Missing data visualization

# Master Orchestrator
fastapi, uvicorn       # API framework
pydantic               # Data validation
bleach, validators     # Security utilities

# Infrastructure (Graceful Fallbacks Available)
motor                  # MongoDB async driver  
aioredis               # Redis async client
confluent-kafka        # Kafka messaging
```

### **Claude Desktop Setup**

1. **Download**: [Claude Desktop](https://claude.ai/download)
2. **Install**: Follow platform-specific instructions
3. **Configure**: Deepline auto-configures MCP connection
4. **Verify**: Test with sample data analysis commands

---

## ğŸ› ï¸ **Installation**

### **Method 1: Standard Installation (Recommended)**

```powershell
# Create workspace
mkdir deepline-workspace
cd deepline-workspace

# Clone repository
git clone https://github.com/your-org/deepline.git
cd deepline/mcp-server

# Install Python dependencies
pip install -r requirements-python313.txt

# Verify installation
python verify_setup.py
```

**Expected Output:**
```
âœ… Python 3.13 detected
âœ… All dependencies installed successfully
âœ… MCP server ready
âœ… Claude Desktop configuration updated
```

### **Method 2: Virtual Environment**

```powershell
# Create virtual environment
python -m venv deepline-env
deepline-env\Scripts\activate

# Install dependencies
pip install -r requirements-python313.txt

# Test installation
python -c "import pandas, evidently, plotly; print('âœ… Core dependencies working')"
```

### **Method 3: Development Setup**

```powershell
# Clone for development
git clone https://github.com/your-org/deepline.git
cd deepline/mcp-server

# Install with dev tools
pip install -r requirements-python313.txt
pip install pytest black ruff mypy

# Run tests to verify
python test_master_orchestrator.py
```

---

## ğŸ—ï¸ **System Architecture**

### **High-Level Architecture**

#### **MCP Server + Claude Desktop**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude Desktop â”‚â”€â”€â”€â”€â”‚   MCP Protocol  â”‚â”€â”€â”€â”€â”‚  Deepline Server â”‚
â”‚   (Frontend)     â”‚    â”‚   (Transport)   â”‚    â”‚   (14 Tools)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Master Orchestrator System**
```
+-----------+      +--------------+      +--------------------+
|  Clients  | ---> |  API Gateway | ---> | Master Orchestrator |
+-----------+      +--------------+      +--------------------+
                                               |      |      |
                                               v      v      v
                                         +----------+ +------------+
                                         |  DSL     | |  LLM       |
                                         |  Parser  | | Translator |
                                         | & Validator|(Guardrails)|
                                         +----------+ +------------+
                                               \      |      /
                                                \     v     /
                                                 +-----------+
                                                 |  Fallback |
                                                 |  Router   |
                                                 +-----------+
                                                      |
                                                      v
                                                +-----------+
                                                | Workflow  |
                                                | Manager   |
                                                +-----------+
                                                      |
         +----------------+          +----------------+         +-----------+
         |    MongoDB     |<-------->|    Kafka       |<------->|   Cache   |
         | (runs, tasks)  |          | (requests,evts)|         | (LLM memo)|
         +----------------+          +----------------+         +-----------+
                                                      |
                                                      v
                                                  +--------+
                                                  | Agents |
                                                  |(EDA,   |
                                                  | Feature,|
                                                  | Model) |
                                                  +--------+
```

### **Core Components**

| Component | Technology | Status | Dependencies |
|-----------|------------|---------|--------------|
| **MCP Server** | Python, asyncio | âœ… Stable | Python 3.12+ |
| **14 Data Tools** | pandas, evidently, sklearn | âœ… Production | Core packages only |
| **Master Orchestrator** | FastAPI, pydantic | âœ… Production | API framework |
| **Security Layer** | bleach, validators | âœ… Production | Security libraries |
| **Infrastructure** | MongoDB, Redis, Kafka | ğŸ”§ Graceful Fallbacks | External services |

### **Data Flow**

1. **User Input**: Natural language command in Claude Desktop
2. **MCP Transport**: Secure communication to Deepline server
3. **Tool Selection**: Automatic routing to appropriate MCP tool
4. **Data Processing**: Execute analysis with built-in security validation
5. **Result Generation**: Format and return structured results to Claude
6. **Workflow Orchestration**: Complex workflows via Master Orchestrator API

---

## ğŸ”§ **Infrastructure Components**

### **ğŸ—„ï¸ MongoDB**

- **Purpose**: Workflow metadata and task history
- **Fallback**: Automatic in-memory storage when unavailable
- **Configuration**: `mongodb://localhost:27017`
- **Collections**: `workflows`, `tasks`, `runs`

### **âš¡ Redis**

- **Purpose**: LLM response caching and rate limiting
- **Fallback**: Automatic in-memory cache when unavailable
- **Configuration**: `redis://localhost:6379`
- **Performance**: Sub-millisecond response times

### **ğŸ“¡ Apache Kafka**

- **Purpose**: Event streaming for enterprise deployments
- **Topics**: `workflow.commands`, `task.events`, `system.alerts`
- **Configuration**: `localhost:9092`
- **Use Case**: Multi-service communication

### **ğŸ“Š Dashboard**

- **Backend**: FastAPI server with WebSocket support
- **Frontend**: React with real-time charts
- **Access**: `http://localhost:3000`
- **Features**: Live workflow monitoring, event streaming

---

## ğŸ“– **Tool Reference**

### **ğŸ“¥ Data Loading & Management**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `load_data` | Load CSV/Excel/JSON files | `"Load sales_data.csv as sales"` |
| `basic_info` | Dataset overview and summary | `"Show basic info for sales dataset"` |
| `list_datasets` | Show all loaded datasets | `"What datasets are currently loaded?"` |

### **ğŸ” Data Quality & Assessment**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `missing_data_analysis` | Analyze missing data patterns | `"Analyze missing data in customer dataset"` |
| `infer_schema` | Detect data types and patterns | `"Infer schema for transaction dataset"` |
| `data_quality_report` | Comprehensive quality assessment | `"Generate quality report for sales dataset"` |

### **ğŸ“Š Statistical Analysis & Visualization**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `statistical_summary` | Descriptive statistics | `"Get statistical summary of revenue dataset"` |
| `detect_outliers` | Find anomalies using IQR/ML methods | `"Detect outliers in price data using IQR"` |
| `create_visualization` | Generate interactive charts | `"Create histogram of customer ages"` |

### **ğŸ¤– ML Model Monitoring**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `drift_analysis` | Compare datasets for data drift | `"Compare training vs production data for drift"` |
| `model_performance_report` | Evaluate model metrics | `"Evaluate model performance with predictions"` |

### **ğŸ”§ Feature Engineering**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `feature_transformation` | Apply Box-Cox, log, binning transforms | `"Apply Box-Cox transformation to sales data"` |

### **ğŸ› Debug & Development**

| Tool | Purpose | Usage Example |
|------|---------|---------------|
| `debug_drift_summary` | Detailed drift analysis | Development and testing |
| `debug_perf_summary` | Performance debugging | Development and testing |

---

## ğŸ”„ **Workflow Examples**

### **Workflow 1: Quick Data Exploration**

```markdown
Goal: Understand a new dataset structure and quality

1. "Load customer_data.csv as customers"
2. "Show me basic info about the customers dataset"
3. "Analyze missing data patterns in customers"
4. "Create a statistical summary of customers"
5. "Detect outliers in customers using IQR method"
6. "Generate a data quality report for customers"

Expected Result: Complete data understanding in ~3 minutes
```

### **Workflow 2: Model Performance Assessment**

```markdown
Goal: Evaluate ML model performance and detect drift

1. "Load baseline_data.csv as baseline"
2. "Load current_data.csv as current"
3. "Analyze drift between baseline and current datasets"
4. "Load model_predictions.csv as predictions"
5. "Generate model performance report for predictions"

Expected Result: Complete performance assessment in ~2 minutes
```

### **Workflow 3: Feature Engineering Pipeline**

```markdown
Goal: Prepare data for machine learning

1. "Load raw_sales_data.csv as raw_sales"
2. "Infer schema for raw_sales dataset"
3. "Apply feature transformation to raw_sales with boxcox and log"
4. "Detect outliers in transformed data"
5. "Generate final data quality report"

Expected Result: ML-ready dataset in ~4 minutes
```

### **Workflow 4: Automated Orchestration (API)**

```bash
# Natural language to structured workflow
curl -X POST http://localhost:8000/workflows \
  -H "Content-Type: application/json" \
  -d '{
    "natural_language": "Load sales data, detect anomalies, and create summary report",
    "client_id": "analytics_team"
  }'

# Returns: Structured workflow with automatic execution
```

---

## ğŸ“ **Project Structure**

```
deepline/
â”œâ”€â”€ ğŸ“ mcp-server/                    # Core MCP server implementation
â”‚   â”œâ”€â”€ ğŸ“„ server.py                 # Main MCP server (14 tools)
â”‚   â”œâ”€â”€ ğŸ“„ launch_server.py          # Server launcher
â”‚   â”œâ”€â”€ ğŸ“„ config.py                 # Configuration management
â”‚   â”œâ”€â”€ ğŸ“„ config.yaml               # System configuration
â”‚   â”œâ”€â”€ ğŸ“„ requirements-python313.txt # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“„ verify_setup.py           # Installation verification
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                  # Utility functions
â”‚   â”œâ”€â”€ ğŸ“„ iris.csv                  # Sample dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ orchestrator/             # Master Orchestrator
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ translator.py         # Natural language processing
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ workflow_manager.py   # Workflow execution
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ security.py           # Input validation & sanitization
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ cache_client.py       # Caching with fallbacks
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ guards.py             # Rate limiting & concurrency
â”‚   â”‚   â””â”€â”€ ğŸ“„ sla_monitor.py        # SLA monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ master_orchestrator_api.py # FastAPI orchestrator service
â”‚   â”œâ”€â”€ ğŸ“„ test_master_orchestrator.py # Comprehensive tests (35 tests)
â”‚   â””â”€â”€ ğŸ“„ reports/                  # Generated analysis reports
â”‚
â”œâ”€â”€ ğŸ“ dashboard/                     # Web dashboard
â”‚   â”œâ”€â”€ ğŸ“ backend/                  # FastAPI backend
â”‚   â”‚   â””â”€â”€ ğŸ“„ main.py              # Dashboard API server
â”‚   â””â”€â”€ ğŸ“ dashboard-frontend/       # React frontend
â”‚       â”œâ”€â”€ ğŸ“„ package.json         # Node.js dependencies
â”‚       â””â”€â”€ ğŸ“ src/                 # React components
â”‚
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â”œâ”€â”€ ğŸ“„ INSTALLATION.md          # Setup guide
â”‚   â”œâ”€â”€ ğŸ“„ USER_GUIDE.md            # User manual
â”‚   â”œâ”€â”€ ğŸ“„ CONFIGURATION.md         # Config reference
â”‚   â”œâ”€â”€ ğŸ“„ EXAMPLES.md              # Workflow examples
â”‚   â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md          # Development guide
â”‚   â””â”€â”€ ğŸ“„ CONNECTIVITY_TEST_REPORT.md # Test results (35/35 passed)
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Infrastructure orchestration
â”œâ”€â”€ ğŸ“„ LICENSE.md                   # Hybrid license information
â”œâ”€â”€ ğŸ“„ LICENSE-APACHE               # Apache 2.0 license text
â”œâ”€â”€ ğŸ“„ LICENSE-BUSL                 # Business Source License text
â””â”€â”€ ğŸ“„ README.md                    # This file
```

---

## ğŸ§ª **Testing**

### **ğŸ” Test Results (Current)**

**Latest Test Run (2025-07-17):**
```
ğŸ‰ PERFECT SUCCESS - Master Orchestrator working flawlessly!
Success Rate: 100% (35 passed / 35 total tests)
Test Duration: ~35 seconds
```

### **ğŸ“Š Test Categories**

| Category | Tests | Status | Coverage |
|----------|-------|--------|----------|
| **Environment & Dependencies** | 9/9 | âœ… Pass | Python, libraries, imports |
| **Configuration System** | 5/5 | âœ… Pass | YAML loading, validation |
| **Core Components** | 8/8 | âœ… Pass | Security, cache, guards, translators |
| **API System** | 4/4 | âœ… Pass | FastAPI routes, endpoints |
| **Infrastructure** | 9/9 | âœ… Pass | Graceful fallbacks when services unavailable |

### **ğŸš€ Running Tests**

```powershell
# Run comprehensive connectivity test
python test_master_orchestrator.py

# Run individual component tests
python test_evidently_tools.py
python test_infer_schema.py
python test_model_performance.py

# Verify complete setup
python verify_setup.py
```

### **ğŸ”§ Test Configuration**

All tests include:
- âœ… **Graceful Degradation**: Tests pass without external infrastructure
- âœ… **Error Handling**: Comprehensive exception testing
- âœ… **Windows Compatibility**: UTF-8 encoding and emoji handling
- âœ… **Real-world Scenarios**: Integration with actual data files

---

## ğŸš¨ **Troubleshooting**

### **ğŸ”§ Common Issues & Solutions**

#### **Issue 1: MCP Server Won't Start**

**Symptoms:**
```
Error: Failed to start MCP server
ImportError: No module named 'evidently'
```

**Solutions:**
```powershell
# Install missing dependencies
pip install -r requirements-python313.txt

# Verify Python version
python --version  # Should be 3.12+

# Check installation
python verify_setup.py
```

#### **Issue 2: Claude Desktop Not Connecting**

**Symptoms:**
- Claude Desktop doesn't show Deepline tools
- No response to data analysis commands

**Solutions:**
```powershell
# Verify server is running
python launch_server.py

# Check Claude Desktop config
python -c "from config import setup_claude_desktop; setup_claude_desktop()"

# Restart Claude Desktop completely
taskkill /IM "Claude.exe" /F
# Then launch Claude Desktop again
```

#### **Issue 3: Master Orchestrator API Issues**

**Symptoms:**
```
HTTP 500 Internal Server Error
Configuration not available
```

**Solutions:**
```powershell
# Check configuration
python -c "from config import load_config; print('Config loaded successfully')"

# Install missing API dependencies
pip install fastapi uvicorn bleach validators aioredis

# Test API
python -m uvicorn master_orchestrator_api:app --reload
curl http://127.0.0.1:8000/health
```

### **ğŸ“‹ Diagnostic Commands**

```powershell
# Complete system check
python verify_setup.py

# Test core components
python test_master_orchestrator.py

# Check dependencies
pip check

# Test individual tools
python -c "
import asyncio
from server import load_data, basic_info
asyncio.run(load_data('iris.csv', 'test'))
result = asyncio.run(basic_info('test'))
print('âœ… MCP tools working:', len(result) > 100)
"
```

---

## ğŸ’¡ **Tips & Best Practices**

### **ğŸš€ Performance Optimization**

#### **Memory Management**
```powershell
# Monitor memory usage during analysis
python -c "import psutil; print(f'Available RAM: {psutil.virtual_memory().available // (1024**3)}GB')"

# Use dataset sampling for large files
"Load first 10000 rows of large_dataset.csv as sample"

# Clear loaded datasets when done
"List all loaded datasets and remove old ones"
```

#### **Efficient Analysis Patterns**
```markdown
# âœ… Optimized workflow
1. Load with sampling: "Load first 5000 rows of data.csv"
2. Quick overview: "Show basic info" 
3. Targeted analysis: "Focus on missing data patterns"
4. Specific visualizations: "Create histogram of key columns"

# âŒ Inefficient approach  
1. Load entire 5GB dataset
2. Run all possible analyses
3. Generate every visualization type
```

### **ğŸ›¡ï¸ Security Best Practices**

- âœ… **Input Sanitization**: All inputs automatically sanitized by security layer
- âœ… **Local Processing**: Data never leaves your machine
- âœ… **Secure Protocols**: MCP uses encrypted communication channels
- âŒ **Avoid Sensitive Paths**: Don't load files from system directories

### **ğŸ“Š Analysis Best Practices**

```markdown
# Start with data understanding
1. "Load dataset and show basic info"
2. "Infer schema to understand data types"
3. "Analyze missing data patterns"

# Then move to specific analysis
4. "Generate statistical summary"
5. "Detect outliers using appropriate method"
6. "Create targeted visualizations"

# Finish with quality assessment
7. "Generate comprehensive data quality report"
```

---

## ğŸ“š **Documentation**

### **ğŸ“– Available Documentation**
- [`docs/INSTALLATION.md`](docs/INSTALLATION.md) - Detailed setup instructions
- [`docs/USER_GUIDE.md`](docs/USER_GUIDE.md) - Complete user manual  
- [`docs/CONFIGURATION.md`](docs/CONFIGURATION.md) - Configuration reference
- [`docs/EXAMPLES.md`](docs/EXAMPLES.md) - Comprehensive workflow examples
- [`docs/CONTRIBUTING.md`](docs/CONTRIBUTING.md) - Development guidelines
- [`docs/CONNECTIVITY_TEST_REPORT.md`](docs/CONNECTIVITY_TEST_REPORT.md) - Test results

### **ğŸš€ API Documentation**
- **Master Orchestrator API**: `http://localhost:8000/docs` (when running)
- **Interactive API Explorer**: Swagger UI with live testing
- **Health Endpoints**: `/health`, `/stats` for monitoring

---

## ğŸ“„ **License**

This project uses a **Hybrid "Adoption + Protection" License**:

### **ğŸ”“ Apache 2.0 - SDK/Client Components**
- Client SDKs and libraries
- Integration examples and documentation  
- Testing frameworks and development tools
- **Commercial use**: âœ… Unrestricted

### **ğŸ›¡ï¸ BUSL 1.1 - Core Server**
- Main MCP server (`server.py`)
- Core analysis tools and algorithms
- Data processing pipeline components
- **Commercial use**: âš ï¸ Contact for licensing
- **Non-commercial use**: âœ… Permitted

### **ğŸ”„ Automatic Conversion**
**After 3 years (2027-01-01):** All components automatically convert to Apache 2.0

See [`LICENSE.md`](LICENSE.md) for complete license terms.

---

## ğŸ“ **Contact**

### **ğŸ‘¨â€ğŸ’» Project Maintainer**
- **LinkedIn**: [Taimoor Awan](https://www.linkedin.com/in/taimoorawan/)
- **Email**: [taimoorintech@gmail.com](mailto:taimoorintech@gmail.com)

### **ğŸ› Issues & Support**
- **GitHub Issues**: Report bugs and request features
- **GitHub Discussions**: Community support and questions
- **Documentation**: Check `docs/` directory for detailed guides

### **ğŸ’¼ Commercial Licensing**
For commercial use of core server components:
- **Contact**: [taimoorintech@gmail.com](mailto:taimoorintech@gmail.com)
- **Response Time**: Within 48 hours
- **Custom Agreements**: Available for enterprise deployments

---

<div align="center">

**Built with â¤ï¸ for the data science community**

*Transforming data analysis through natural language interfaces*

[ğŸŒŸ Star on GitHub](https://github.com/your-org/deepline) â€¢ [ğŸ“ Report Issues](https://github.com/your-org/deepline/issues) â€¢ [ğŸ’¬ Join Discussions](https://github.com/your-org/deepline/discussions)

</div>