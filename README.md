# Deepline â€“ The Endâ€‘toâ€‘End MLOps Powerhouse

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-Apache%202.0%20%7C%20BUSL%201.1-green.svg)](LICENSE.md)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)](https://github.com/DeepExtrema/Deepline)
[![Version](https://img.shields.io/badge/Version-2.1.0-orange.svg)](https://github.com/DeepExtrema/Deepline/releases)

**Version**: 2.1.0  
**Status**: Production ready with deadlock monitoring and graceful cancellation support  
**Last updated**: January 2024 (see [CHANGELOG.md](CHANGELOG.md) for release notes).

Imagine turning raw data into insights and models in minutesâ€”no code required. Deepline isn't just an orchestration tool; it's your complete data science studio. Start with dragâ€‘andâ€‘drop EDA, where the EDA Agent handles data loading, statistics, missingâ€‘data analysis, outlier detection and stunning, publicationâ€‘ready visualisations. Move seamlessly into feature engineering, with configurable pipelines that transform, encode and select the best featuresâ€”all through an intuitive interface. Finally, fire up model training via builtâ€‘in, noâ€‘code workflows that leverage the MLOps engine to train and evaluate models on the fly.

At its core, Deepline harnesses a Master Orchestrator that orchestrates every taskâ€”dispatching them to specialist agents and tracking progress. A Hybrid API lets you describe workflows in plain language and watch them transform into executable pipelines, while deadlock monitors and graceful cancellation keep long-running jobs resilient and safe. Your work is visualised in real time through the observability dashboard, delivering live charts and event streams.

Whether you're a data enthusiast or a seasoned data scientist, Deepline makes the entire journeyâ€”from EDA to feature engineering to model trainingâ€”feel like magic.

## ğŸ—ï¸ **Architecture Overview**

The system follows a modular microservices design with these core components:

- **Master Orchestrator** â€“ a FastAPI service that manages workflow definitions, dispatches tasks to specialist agents and tracks their execution. It exposes a REST API for dataset uploads, workflow creation and artifact retrieval.

- **EDA Agent** â€“ a microservice providing advanced data loading, statistical summaries, missingâ€‘data analysis, outlier detection and publicationâ€‘ready visualisation. It is built on FastAPI and integrates with Pandas, NumPy, scikitâ€‘learn and Redis for caching.

- **Hybrid API** â€“ an asynchronous translation service that converts naturalâ€‘language requests into a domainâ€‘specific language (DSL) for workflow execution. It enables nonâ€‘blocking translation, tokenâ€‘based polling, Redisâ€‘backed queuing and comprehensive validation of user input.

- **Deadlock Monitor & Graceful Cancellation** â€“ a background service that scans for stuck workflows, cancels them safely and provides API endpoints for manual cancellation.

- **Observability Dashboard** â€“ a React/Node.js application providing realâ€‘time charts, recent run status and live event streaming. The dashboard connects to the FastAPI backend via REST and WebSockets and depends on Kafka and MongoDB.

Together, these components form a scalable microservices architecture capable of orchestrating complex dataâ€‘science workflows while providing realâ€‘time monitoring and robust error handling.

### **ğŸ§± System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Clients            â”‚    â”‚        Observability UI        â”‚
â”‚  (CLI, SDKs, React dashboard) â”‚    â”‚    (React + Recharts)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ REST / WebSocket                    â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—               â”‚
â•‘      API Layer â€“ FastAPI app        â•‘               â”‚
â•‘  â€¢ /workflows/dsl   â€“ DSL executor  â•‘               â”‚
â•‘  â€¢ /workflows/translate â€“ async NL  â•‘               â”‚
â•‘  â€¢ /translation/{token} â€“ polling   â•‘               â”‚
â•‘  â€¢ /runs/{id}/cancel â€“ cancellation â•‘               â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚
                â”‚ validated DSL                       â”‚
                â–¼                                     â”‚
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         Master Orchestrator Service (FastAPI)         â•‘
â•‘  â€¢ Workflow management, scheduling & tracking         â•‘
â•‘  â€¢ Interfaces with agents via REST                    â•‘
â•‘  â€¢ Persists runs & tasks in MongoDB                   â•‘
â•‘  â€¢ Publishes events to Kafka                          â•‘
â•‘  â€¢ Integrates deadlock monitor & SLA monitor          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                â”‚ task requests / events (Kafka)        
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ EDA Agent (FastAPI)    â”‚   Future agents (FE,   â”‚ Drift Detectors â”‚
        â”‚ â€¢ Data loading         â”‚     ML, Model serving) â”‚  (Evidently)    â”‚
        â”‚ â€¢ Statistical analysis â”‚                        â”‚                 â”‚
        â”‚ â€¢ Visualisation        â”‚                        â”‚                 â”‚
        â”‚ â€¢ Outlier detection    â”‚                        â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Additional infrastructure includes MongoDB (for run persistence), Redis (for caching and concurrency control) and Kafka (for interâ€‘service messaging). The dashboard communicates with the backend via REST and WebSocket endpoints.

## âœ¨ **Key Features**

- **Hybrid API with async translation** â€“ submit natural language descriptions of workflows and retrieve a token for asynchronous translation. Poll for results via the `/translation/{token}` endpoint and execute DSL workflows through `/workflows/dsl`.

- **Intelligent scheduling** â€“ the Master Orchestrator prioritises tasks based on urgency and resource availability and supports retries and concurrency limits.

- **Exploratory Data Analysis** â€“ the EDA Agent provides detailed dataset summaries, correlation matrices, missingâ€‘data visualisation and outlier detection using IQR, Isolation Forest and Local Outlier Factor methods. It generates highâ€‘quality visualisations (300 DPI PNG) ready for publications.

- **Deadlock monitoring and graceful cancellation** â€“ automatic detection of stuck workflows with configurable thresholds (default: 15 minutes per task, 1 hour per workflow) and APIs to cancel or forceâ€‘cancel runs.

- **Realâ€‘time observability** â€“ live event streams, recent runs view and performance charts through the dashboard.

- **Containerized deployment** â€“ Dockerfile and dockerâ€‘compose.yml enable multiâ€‘service deployments with Nginx load balancing and automatic health checks.

- **Security & monitoring** â€“ input sanitization, CORS, rate limiting, API key support and comprehensive health endpoints.

## ğŸ› ï¸ **Tech Stack & Dependencies**

Deepline relies on modern Python and JavaScript ecosystems. Below are the primary dependencies and their minimum versions (for a complete lockfile with hashes see `mcpâ€‘server/requirements.lock`).

| Category | Key packages (min version) |
|----------|---------------------------|
| **Core framework** | `mcp[cli] â‰¥ 1.10.1`, `pydantic â‰¥ 2.11.7` |
| **Data processing & analysis** | `pandas â‰¥ 2.2.0`, `numpy â‰¥ 2.1.0`, `pyarrow â‰¥ 20.0.0` |
| **Machine learning** | `scikitâ€‘learn â‰¥ 1.7.0`, `scipy â‰¥ 1.15.0`, `pyod â‰¥ 2.0.5` |
| **Data quality & profiling** | `evidently â‰¥ 0.7.9`, `pandasâ€‘profiling â‰¥ 3.2.0`, `missingno â‰¥ 0.5.2` |
| **Visualisation** | `matplotlib â‰¥ 3.10.0`, `seaborn â‰¥ 0.13.0`, `plotly â‰¥ 5.24.0` |
| **Server & API** | `fastapi â‰¥ 0.104.0`, `uvicorn[standard] â‰¥ 0.24.0`, `httpx â‰¥ 0.25.0` |
| **Messaging & database** | `confluentâ€‘kafka â‰¥ 2.3.0`, `motor â‰¥ 3.3.0`, `pymongo â‰¥ 4.6.0` |
| **Caching & storage** | `redis â‰¥ 5.0.0`, `aioredis â‰¥ 2.0.0` |
| **Configuration & utilities** | `pyyaml â‰¥ 6.0.1`, `pythonâ€‘multipart â‰¥ 0.0.6` |
| **Resilience & rate limiting** | `tenacity â‰¥ 8.2.0`, `slowapi â‰¥ 0.1.9` |
| **Security & validation** | `bleach â‰¥ 6.1.0`, `validators â‰¥ 0.22.0` |
| **LLM & guardrails (optional)** | `guardrailsâ€‘ai â‰¥ 0.5.0`, `openai â‰¥ 1.0.0` |
| **Frontâ€‘end** | Node.js 18+, React 18, Recharts for charts |

### **Prerequisites:**

- **Python 3.13+** (3.12+ is supported on Windows)
- **Node.js 18+** for the React dashboard
- **Docker & Docker Compose** to run MongoDB, Kafka, Redis and the containerised services
- **Git** for version control

## ğŸ§‘â€ğŸ’» **Installation & Setup**

Follow these steps to get Deepline running on your machine. Detailed Windowsâ€‘specific instructions are available in [docs/INSTALLATION.md](docs/INSTALLATION.md).

### **1. Clone the repository**
```bash
git clone https://github.com/DeepExtrema/Deepline.git
cd Deepline
```

### **2. Start infrastructure services**
Deepline relies on MongoDB, Redis and Kafka. The repository provides a `dockerâ€‘compose.yml` in `mcpâ€‘server/` to spin these up quickly.

```bash
cd mcp-server
docker-compose up -d
```

This will launch the databases and message queue needed by the orchestrator and EDA agent. You can monitor the containers via `docker-compose ps`.

### **3. Set up a Python environment**
Create a virtual environment and install the Python dependencies. Use Python 3.13+ to ensure compatibility. For example:

```bash
# create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# install backend dependencies
pip install -r requirements-python313.txt
```

The `requirements-python313.txt` file specifies compatible versions across the data science, machine learning and web frameworks.

### **4. Install Node.js dependencies (dashboard)**
If you wish to run the realâ€‘time dashboard, install the frontâ€‘end dependencies and start the development server:

```bash
cd dashboard/dashboard-frontend
npm install
npm start
```

This will run the React app on port 3000 by default.

### **5. Run the backend services**
In separate terminals (or using process manager scripts), launch the Master Orchestrator and EDA Agent:

```bash
# Master Orchestrator (port 8000)
python start_master_orchestrator.py

# EDA Agent (port 8001)
python start_eda_service.py
```

The services will be available at:

- **Master Orchestrator**: http://localhost:8000 â€“ API root & health check
- **EDA Agent**: http://localhost:8001 â€“ EDA API and docs
- **Dashboard UI**: http://localhost:3000 â€“ frontâ€‘end interface

Alternatively you can use Docker Compose to build and run all services together:

```bash
docker-compose up -d
```

This will build the containers, expose ports 80/443 via Nginx and run health checks.

### **6. Configuration**
Deepline reads configuration from `mcp-server/config.yaml`, environment variables and commandâ€‘line arguments. The YAML file defines data processing limits, quality thresholds, outlier detection parameters, visualisation settings and logging options.

You can override these defaults by editing `config.yaml` or setting environment variables such as `DEEPLINE_OUTPUT_DIR`, `DEEPLINE_LOG_LEVEL` and `DEEPLINE_MAX_WORKERS`. See [docs/CONFIGURATION.md](docs/CONFIGURATION.md) for detailed explanations and tuning examples.

## ğŸƒâ€â™‚ï¸ **Usage**

### **Upload a dataset**
Use the Master Orchestrator's dataset upload endpoint to add a CSV file:

```bash
curl -X POST "http://localhost:8000/datasets/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_dataset.csv" \
  -F "name=my_dataset"
```

### **Start a workflow**
Define a workflow with a list of tasks (agent, action and arguments) and send it to the orchestrator:

```bash
curl -X POST "http://localhost:8000/workflows/start" \
  -H "Content-Type: application/json" \
  -d '{
        "run_name": "eda_analysis",
        "tasks": [
          {
            "agent": "eda_agent",
            "action": "load_data",
            "args": {"path": "your_dataset.csv", "name": "my_dataset"}
          },
          {
            "agent": "eda_agent",
            "action": "create_visualization",
            "args": {"name": "my_dataset", "chart_type": "correlation"}
          }
        ]
      }'
```

The response will include a `run_id` that can be used to poll status via `GET /runs/{run_id}/status` or fetch artefacts via `GET /runs/{run_id}/artifacts`.

### **Use the Hybrid API**
To translate natural language into DSL asynchronously:

```bash
# Submit translation request
curl -X POST "http://localhost:8000/workflows/translate" \
  -H "Content-Type: application/json" \
  -d '{"text": "Create a workflow that processes data and generates reports"}'

# Poll translation status
curl "http://localhost:8000/translation/{token}"
```

Once the translation is completed you will receive a DSL description of the workflow, which can be executed via `POST /workflows/dsl`.

### **Explore the API**
Each FastAPI service exposes interactive API documentation at `/docs` (Swagger UI) and `/redoc`. The main endpoints are listed in `mcp-server/PRODUCTION_DEPLOYMENT_SUMMARY.md`.

### **Observability dashboard**
Navigate to http://localhost:3000 to open the React dashboard. It provides realâ€‘time charts of event activity, recent runs and a live feed of Kafka events.

## âš™ï¸ **Customisation & Extension**

The platform is built with extensibility in mind:

- **Add new agents**: implement a FastAPI microservice with the desired functionality, register its URL in `master_orchestrator_api.get_agent_url` and define tasks referencing the new agent.

- **Tune analysis**: adjust thresholds and sample sizes in `config.yaml` or override via environment variables.

- **Add visualisations or metrics**: extend the EDA Agent functions and update the API models in `eda_agent.py`.

- **Scale services**: deploy multiple instances behind the provided Nginx load balancer and use Docker/Kubernetes for orchestration.

## ğŸ“„ **License**

Deepline uses a hybrid licensing model to balance open innovation with sustainability:

- **Apache 2.0** for SDKs, client libraries, examples and documentation â€“ commercial use, modification and redistribution are permitted.

- **Business Source License 1.1 (BUSL)** for the core server â€“ free for nonâ€‘commercial use; commercial use or redistribution requires a licence agreement. The BUSL portion automatically converts to Apache 2.0 three years after release.

For full terms see [LICENSE.md](LICENSE.md), [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-BUSL](LICENSE-BUSL). If you plan to build a commercial product or deploy Deepline for customers, please contact the maintainers at **licensing@deepline.ai**.

## ğŸ¤ **Contributing**

We welcome contributions from the community! To get started:

1. **Fork this repository** and clone your fork locally
2. **Create a virtual environment** and install development dependencies (`pip install -r requirements-python313.txt` plus `pytest`, `black`, `ruff`, `mypy`)
3. **Create a feature branch** (`git checkout -b feature/your-feature`)
4. **Write clear, wellâ€‘tested code** and adhere to the PEP 8 style. Use Black for formatting, Ruff for linting and MyPy for type checking
5. **Run tests** using pytest and ensure all tests pass before submitting a pull request
6. **Submit a PR** with a clear description and reference any related issues or features

See [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md) for detailed guidelines on code style, commit message format, testing strategy and the PR checklist.

## ğŸ“š **Documentation & Examples**

Deepline includes extensive documentation in the `docs/` directory:

- **[Installation Guide](docs/INSTALLATION.md)** â€“ stepâ€‘byâ€‘step setup instructions including Windowsâ€‘specific steps and verification procedures
- **[Configuration Guide](docs/CONFIGURATION.md)** â€“ description of the YAML configuration and environment variables with tuning tips
- **[Examples & Use Cases](docs/EXAMPLES.md)** â€“ a collection of practical workflows and advanced scenarios to try out
- **[Hybrid API Documentation](docs/HYBRID_API.md)** â€“ full specification of the async translation API including request/response formats
- **[Connectivity Test Report](docs/CONNECTIVITY_TEST_REPORT.md)** â€“ record of a comprehensive connectivity test demonstrating 100% success and highlighting fallback mechanisms for missing infrastructure

Refer to these documents to deepen your understanding of the system.

## ğŸ› ï¸ **Troubleshooting & Support**

Common issues and fixes are documented in the various guides:

- **WebSocket or API failures**: ensure that the backend services are running on the correct ports and that CORS settings permit your client origin
- **Missing data or charts not rendering**: verify MongoDB connectivity and that Kafka topics contain events
- **Port conflicts**: change the port arguments when launching uvicorn or set the PORT environment variable for React

For further assistance, please open an issue on the GitHub repository or start a discussion. License questions should be directed to **licensing@deepline.ai**.

## ğŸ“Œ **Roadmap**

Upcoming features and enhancements include JWT authentication, advanced rate limiting, realâ€‘time notifications, machineâ€‘learning model agents, enhanced monitoring, Kubernetes deployment and multiâ€‘tenant support. See [CHANGELOG.md](CHANGELOG.md) for a history of changes and planned features.

## ğŸ§¾ **Acknowledgements**

Deepline builds upon openâ€‘source libraries such as FastAPI, Pandas, scikitâ€‘learn, NumPy and many others. We thank their maintainers and contributors for their efforts. The project also draws inspiration from best practices in modern MLOps and data engineering.

---

**Â© 2024 Deepline. All rights reserved.**  
*Building the future of data analytics through sustainable open source innovation.*
